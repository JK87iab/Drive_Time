{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate drive time/ OSRM server\n",
    "Author: Jonas Krueger\n",
    "last Edit: 01/26/18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import requests \n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import aiohttp\n",
    "import async_timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup is based on an OSRM backend running on a (cloud) server. I use google cloud, but any setup will work.\n",
    "\n",
    "1. Open connection to SQL server to load base table\n",
    "    + Base table has all lang/lat pairs, for which we want to calculate drive time and distance\n",
    "2. Since we donâ€™t want to read in the complete table we looping through chunks of it\n",
    "    + With `mod(VALUE,100)` we can split the base table in 100 equal parts. Here we use household_id\n",
    "    + Each chunk (0-99) will be read in 1000 rows at a time with `pd.read_sql_query(\"\"\" select [...] where chunck = \"\"\" + str(chunk) + ';' , conn, chunksize= 1000):`\n",
    "3. Build URLs for the OSRM server \n",
    "    + We just need to build a list of string `'http://OSRM IP/route/v1/driving/' + Long/lat ` to pass to our OSRM server\n",
    "4. To speed up http requests call we use the **asyncio** package. https://docs.python.org/3/library/asyncio.html and https://pawelmhm.github.io/asyncio/python/aiohttp/2016/04/22/asyncio-aiohttp.html\n",
    "    + Allows us to send requests to the OSRM server without waiting on an response. \n",
    "5. We get back a json object from OSRM, we parse this and upload it back to the SQL server (I also write a csv file for long term storage) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del cursor\n",
    "\n",
    "#Netezza\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={XXXX};'\n",
    "    'UID=XXXX;'\n",
    "    'SERVER=XXXX;'\n",
    "    'DATABASE=XXXX;'\n",
    "    'PWD=XXXX;'\n",
    "    )\n",
    "\n",
    "conn2 = pyodbc.connect(\n",
    "    'DRIVER={XXXX};'\n",
    "    'UID=XXXX;'\n",
    "    'SERVER=XXXX;'\n",
    "    'DATABASE=XXXX;'\n",
    "    'PWD=XXXX;'\n",
    "    )\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor2 = conn2.cursor()\n",
    "\n",
    "\n",
    "#Functions\n",
    "#ToDo\n",
    "## Server IP and Long/Lat colum names as user input as user inpuut\n",
    "def create_urls(input_table):\n",
    "    url_list = []\n",
    "    for index, row in input_table.iterrows():\n",
    "        url ='http://IP:PORT/route/v1/driving/' + str(row['LONGITUDE_ADDR']) + ',' + str(row['LATITUDE_ADDR']) + ';' + str(row['LONGITUDE_AUSA']) + ',' + str(row['LATITUDE_AUSA']) + \"?overview=simplified\"\n",
    "        url_list.append(url)\n",
    "    \n",
    "    return url_list\n",
    "\n",
    "####### OSRM calls\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.json()\n",
    "        \n",
    "async def run():\n",
    "    \n",
    "    tasks = []\n",
    "   \n",
    "    \n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    async with ClientSession() as session:\n",
    "       \n",
    "            try:\n",
    "                for i in urls:\n",
    "                    task = asyncio.ensure_future(fetch(i, session))\n",
    "\n",
    "                    tasks.append(task)\n",
    "\n",
    "                responses = await asyncio.gather(*tasks)\n",
    "                return(responses)\n",
    "            except:\n",
    "               \n",
    "                sys.exit(\"Error: at\" + chunk)\n",
    "        # you now have all response bodies in this variable\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "#We loop over chuncks of 1000 in our sql datafram\n",
    "for chunk in range(97, 100):\n",
    "    print(chunk)\n",
    "    counter = 0 \n",
    "    for df in pd.read_sql_query(\"\"\" select HOUSEHOLD_ID, LATITUDE_ADDR, LONGITUDE_ADDR, AUSA_STORE_ID,\n",
    "    LATITUDE_AUSA, LONGITUDE_AUSA ,CURRENT_DATE as time_stamp from ahutstanl..hh_pref_store where chunck = \"\"\" + str(chunk) + ';' , conn, chunksize= 1000):\n",
    "\n",
    "        counter= counter+1\n",
    "        #print(counter)\n",
    "        #create urls\n",
    "        urls = create_urls(df)       \n",
    "\n",
    "        #Get drivetime    \n",
    "        loop = asyncio.get_event_loop()\n",
    "        future = asyncio.ensure_future(run())\n",
    "        stime = time.time()\n",
    "        responses = loop.run_until_complete(future)\n",
    "        dur = time.time() - stime\n",
    "        print(\"Calculated %d distances in %.2f seconds: %.0f per second\" % (len(responses),\n",
    "                                                                                        dur,\n",
    "                                                                                       len(responses)/dur))\n",
    "        #Parse json object \n",
    "        final = []\n",
    "        for i in responses:\n",
    "            if i['code'] == 'Ok':\n",
    "                status = i['code']\n",
    "                tot_time_s = i['routes'][0]['duration']\n",
    "                tot_dist_m = i['routes'][0]['distance']\n",
    "                out =  [status,tot_time_s,tot_dist_m]\n",
    "\n",
    "            else:\n",
    "                status = i['code']\n",
    "                tot_time_s = 999999\n",
    "                tot_dist_m = 999999\n",
    "                out =  [status,tot_time_s,tot_dist_m]\n",
    "\n",
    "            final.append(out)\n",
    "\n",
    "\n",
    "        df1 = pd.DataFrame(final)\n",
    "        df_c = pd.concat([df1.reset_index(drop=True), df], axis=1)\n",
    "        #df_c.iloc[:,[0,1,2,3,4,9,10]].round(2).to_csv('out/output_osrm_' + str(counter) + '.csv', encoding='utf-8', index=False,header  = False )\n",
    "        df_c.to_csv('out/output_osrm_' + str(counter) + '_'+ str(chunk) + '.csv', encoding='utf-8', index=False, sep = '|' , header  = False )\n",
    "\n",
    "        #Insert into sql\n",
    "        cursor2.execute(\"\"\"  INSERT INTO ahutstanl..ausa_drive_tim_hh\n",
    "                  SELECT * FROM\n",
    "                  EXTERNAL 'C:/Users/JKrueger/Documents/Scripts/Python_notebook/out/output_osrm_\"\"\"  + str(counter) + '_'+ str(chunk) + \"\"\".csv'\n",
    "                  USING\n",
    "                  (   LOGDIR 'C:/Users/JKrueger/Documents/Scripts/Python_notebook/'\n",
    "                  DELIMITER '|'\n",
    "                  QUOTEDVALUE 'DOUBLE'\n",
    "                  Y2BASE 2000\n",
    "                  ENCODING 'internal'\n",
    "                  REMOTESOURCE 'ODBC'\n",
    "                  ESCAPECHAR '\\'\n",
    "                  )     \"\"\")\n",
    "        \n",
    "       \n",
    "        \n",
    "        conn2.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
